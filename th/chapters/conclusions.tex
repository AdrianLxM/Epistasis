
%-----------------------------------------------------------------------------
\chapter{Conclusions \label{ch:concl}}
%-----------------------------------------------------------------------------

%---
\section{Contributions}
%---

In this thesis we contributed to three steps involved in the analysis of sequencing data and identifying the links between genetic variants and disease. Each step is characterized by very different problems that need to be addressed.
					
\begin{itemize}
\item[i)] The first step is to reduce large amounts of information generated by high throughput experiments into a manageable summary. In our case, it involves reducing the raw sequencing information to a variant call set, but it could be any other features to be analyzed (RNA expression, transcript structure, enrichment peaks, genome reference assembly, etc.). This is mainly done by mapping reads into a reference genome and then using variant call algorithms. This step is characterized by requiring fast parallel algorithms and usually, due to the amount of data involved, I/O can be one of the bottlenecks. Algorithms that work on ``chunks of data" instead of the whole data-set are preferred, and in many cases exist, because working on disjoint data makes the problem easier to parallelize. Usually several stages of these highly specialized algorithms are combined into a ``data analysis pipeline". Programming data analysis pipelines is not trivial since it requires process coordinations, robustness, scalability and flexibility (data processing pipelines, particularly in research environments, tend to change often). Although many data pipeline solutions are available usually in the form of libraries, these libraries tend to make pipeline programming cumbersome or create new programming paradigms thus introducing a steep learning curve. In Chapter \ref{ch:bds}, we address problems related to pipeline programming in a novel way by creating a new programming language, BDS, that simplifies the creation of robust, scalable and flexible data pipelines. Although the main rationale behind the development of BDS was managing our sequencing data pipelines, it is a flexible programming language that can be applied to many large data pipelines.

\item[ii)] The second step in our data analysis consists of functional annotation, prioritization and filtering of genetic variants. The main concern in the annotation step is performing an adequate filtering of what should be considered relevant variants for our experiment from irrelevant ones. Until not long ago there were no publicly available packages for functional annotation of genomic variants, in chapter \ref{ch:snpeff} we introduced SnpEff \& SnpSift, two variant annotation solutions that quickly became widely adopted by the research community. 
%In Chapter \ref{ch:snpeff} we describe the challenges of variant annotations and some of the solutions we implemented in our algorithms.

\item[iii)] Finally, in Chapter \ref{ch:gwas}, we analyze the problem of finding genetic links to complex disease. This is known to be a difficult problem affected by several hidden co-factors that bias the results (e.g. population structure). Furthermore there are limitations, evidenced by missing heritability, implying that genomic links to complex disease may not be found using traditional GWAS methodologies. We believe that alternative models that combine higher level information, may help to boost statistical significance. 

	\begin{itemize}
		\item[iii.a)] We proposed a new methodology for addressing a difficult problem: detection of interacting genomic loci (epistasis) that affect disease risk. Our models combine genotype information and co-evolutionary evidence. We show that efficient algorithms make these studies computationally feasible, albeit using large computational resources.
	
		\item[iii.b)] We were involved in a major project on GWAS of type II diabetes using a cohort of multi-ethnic unrelated individuals which results uncovered new genes linked to diabetes. We applied our epistatic GWAS models to data form this type II diabetes sequencing study of over 13,000 individuals finding suggestive evidence of interaction.
			\end{itemize}
	
\end{itemize}

These three chapters (three steps) complete our journey from ``raw data" to ``biological insight" trying to find the genetic causes of complex disease.

%---
\section{Future work}
%---

Here we propose several improvements, extensions and future directions of work for each of the topics discussed in this thesis \\

\paragraph{BigDataScript}
We are adding native support for new clusters and frameworks, such as LSF, Mesos, Kubertes as well as a \textit{``Generic cluster"} API which allows the user to customize BigDataScript for any cluster or framework by encapsulating task management via user defined scripts. On the language specification side, we are exploring ways to add functional constructs such as \texttt{map}, \texttt{apply}, \texttt{filter} as well as support for \textit{map/reduce} and \textit{scatter/gather} which are convenient ways to define some problems in data pipeline programming. Finally we, will be incorporating user-defined data structures or a basic class mechanism (BDS currently supports maps and list).

\paragraph{Variant annotations} In an effort coordinated with the developers of other annotations tools (such as ANNOVAR, ENSEMBL’s Variant effect predictor -VEP-, JAnnovar, etc.) we are creating new annotation standard for VCF files. We are actively collaborating with the \textit{``Global Alliance for genomic and Health"} (GA4GH) on the creation of variant annotation specification \& API definitions. We plan to extend SnpEff's variant annotation capabilities to \textit{haplotype-based} annotations, which means taking into account phasing information to calculate compound variant effects (e.g. phased SNPs affecting the same codon or compensating frame shifts within the same DNA strand). Finally, we are using information theoretic analysis of splice sites from several species in order to improve splicing effect predictions.

\paragraph{GWAS Epistasis}
As future work, we'd like to evaluate the possibility of incorporating contextual information, such as protein domain, in order to build more specific co-evolutionary models. Other improvements include further optimization of logistic regression and Bayes factor algorithms since any improvement greatly reduces computational times. We also plan to use our methods on even larger type II diabetes cohorts that are currently being sequenced. Finally, we are evaluating the possibility of incorporating higher order interactions by clustering genes from our variant-pairs analysis and then evaluate them in a joint analysis.

%---
\section{Perspectives}
%---

Genomic research for complex disease is trending towards larger and larger cohorts in order to improve statistical power. Some years ago, projects involving hundreds to a thousand individuals were common. To put this in perspective, that’s the population of a village, or a small town. Nowadays, projects like the those lead by the T2D consortia sequence in the order of 20,000 people (i.e. the population of a large town). I am aware, through personal communications with other researchers, that projects being drafted for sequencing over 100,000 individuals (i.e. the population of a whole city). This quest for ever bigger sample sizes shows how elusive the genetic causes of complex diseases are. It might be true that huge sample sizes are needed to uncover risk loci, but perhaps one of the reasons why traditional GWAS studies are not finding as many associations as expected is just that we they are looking at the wrong place by not taking into account other possibilities, such as epistasis.
%The methods developed here aim to help in the processing of these huge datasets (BDS), the annotation and prioritization of variants (SnpEff), and find association between interacting variants and disease risk (epistatic GWAS). 
